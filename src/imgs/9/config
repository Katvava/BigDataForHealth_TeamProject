import os
import pickle

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import torch.optim as optim
from mydatasets import MedicalDiagnosisDataset, visit_collate_fn

from models.my_rnn_elmo import GRU_ELMO
from utils import train, evaluate
from plots import plot_learning_curves, plot_confusion_matrix
import numpy as np

# Set a correct path to the data files that you preprocessed

PATH_TEST_SEQS = "../data/saved_features/test_data.pkl"
PATH_TEST_LEN = "../data/saved_features/test_l_before_padding.pkl"

PATH_WEIGHT = "./model_weights/MyRNNELMo.pth"

NUM_EPOCHS = 500
BATCH_SIZE = 128
USE_CUDA = True  # Set 'True' if you want to use GPU
NUM_WORKERS = 0

learning_rate = 0.0001

device = torch.device("cuda" if torch.cuda.is_available() and USE_CUDA else "cpu")
torch.manual_seed(1)
if device == "cuda":
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

print('===> Loading entire datasets')
test_seqs = pickle.load(open(PATH_TEST_SEQS, 'rb'))
test_len = pickle.load(open(PATH_TEST_LEN, 'rb'))

test_dataset = MedicalDiagnosisDataset(test_seqs['X'], test_seqs['y'], test_len)

# batch_size for the test set should be 1 to avoid sorting each mini-batch which breaks the connection with patient IDs
test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False, collate_fn=visit_collate_fn,
                         num_workers=NUM_WORKERS)

ELMO_DIM = 1024
HIDDEN_DIM = 64
OUTPUT_DIM = 2
N_LAYERS = 1
BIDIRECTIONAL = False
DROPOUT = 0.4

model = torch.load(PATH_WEIGHT)
criterion = nn.BCEWithLogitsLoss()
model.to(device)
criterion.to(device)

best_val_acc = 0.0
test_losses, test_accuracies = [], []
all_valid_results = []

for epoch in range(NUM_EPOCHS):
    test_loss, test_accuracy, valid_results = evaluate(model, device, test_loader, criterion)
    all_valid_results.append(valid_results)

    test_losses.append(test_loss)
    test_accuracies.append(test_accuracy)

print('Average loss: {}'.format(np.mean(test_losses)))
print('Average accuracy: {}'.format(np.mean(test_accuracies)))

zx = 1


import torch.nn as nn
import torch
from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence

class GRU_ELMO(nn.Module):
    def __init__(self,
                 dim_input,
                 hidden_dim,
                 output_dim,
                 n_layers,
                 bidirectional,
                 dropout):
        super(GRU_ELMO, self).__init__()

        rnn_input_size = dim_input

        self.rnn = nn.GRU(rnn_input_size,
                          hidden_dim,
                          n_layers,
                          bidirectional=bidirectional,
                          batch_first = True,
                          dropout=0 if n_layers < 2 else dropout)

        # self.fc1 = nn.Linear(dim_input, dim_input//4)
        # self.fc2 = nn.Linear(dim_input//4, dim_input//16)
        # self.fc3 = nn.Linear(dim_input//16, rnn_input_size)

        if bidirectional == True:
            self.fc4 = nn.Linear(hidden_dim * 2, output_dim)
        else:
            self.fc4 = nn.Linear(hidden_dim, output_dim)

        self.dropout = nn.Dropout(p=dropout)
        self.relu = nn.ReLU()
        self.selu = nn.SELU()

    def forward(self, input_tuple):
        seqs, lengths = input_tuple

        x1 = pack_padded_sequence(seqs, lengths, batch_first = True)
        output_all_steps, h = self.rnn(x1)
        output_all_steps = pad_packed_sequence(output_all_steps)

        if self.rnn.bidirectional:
            h = self.dropout(torch.cat((h[-2, :, :], h[-1, :, :]), dim=1))
        else:
            h = self.dropout(h[-1, :, :])

        x2 = self.selu(self.dropout(self.fc4(h)))

        return x2

#
# X = torch.rand([32, 100, 1024])
# model = GRU_ELMO(1024, 64,  2, 2, True, 0.3)
# y = model([X, [32]*32])

